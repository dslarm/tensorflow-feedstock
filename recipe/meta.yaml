{% set version = "2.19.0" %}
{% set estimator_version = "2.15.0" %}
{% set build = 3 %}

{% if cuda_compiler_version != "None" %}
{% set build = build + 200 %}
{% endif %}

{% if microarch_level is undefined %}
{% set microarch_level = "1" %}
{% endif %}

{% set build = build + 25*(microarch_level | int - 1) %}

# Quite often libml_dtypes-headers and ml_dtypes diverge.
# https://github.com/tensorflow/tensorflow/blob/v2.18.0/third_party/py/ml_dtypes/workspace.bzl
{% set libml_dtypes_version = "0.5.1" %}
{% set ml_dtypes_version = "0.5.1" %}

package:
  name: tensorflow-split
  version: {{ version }}

source:
  - url: https://github.com/tensorflow/tensorflow/archive/refs/tags/v{{ version.replace(".rc", "-rc") }}.tar.gz
    sha256: 4691b18e8c914cdf6759b80f1b3b7f3e17be41099607ed0143134f38836d058e
    patches:
      - patches/0001-loosen-requirements.patch
      - patches/0002-Add-additional-absl_synchronization-linkage-to-gRPC.patch
      - patches/0003-Fix-missing-abseil-linkages.patch
      - patches/0004-Fix-protobuf_python-for-systemlibs.patch
      - patches/0005-Add-absl_log-systemlib.patch
      - patches/0006-Omit-linking-to-layout_proto_cc-if-protobuf-linkage-.patch
      - patches/0007-Fix-further-abseil-linkage.patch
      - patches/0008-Add-constraint-to-pybind11-systemlib.patch
      - patches/0009-Different-file-ending-for-flatbuffers-LICENSE.patch
      - patches/0010-Use-correct-hermetic-python.patch
      - patches/0011-Add-well_known_types_py_pb2-to-protobuf-systemlib.patch
      - patches/0012-Add-protobuf-toolchain.patch
      - patches/0013-fix-genproto.patch
      - patches/0014-Remove-some-usage-of-absl-str_format-in-CUDA.patch  # [(cuda_compiler_version or "").startswith("11")]
      - patches/0015-Adjust-relative-path-for-libdevice.patch            # [(cuda_compiler_version or "").startswith("11")]
      - patches/0016-Link-to-absl_log_flags-instead-of-absl_flags.patch
      - patches/0017-Update-ABSL-Log-Definition-for-libabsl_vlog_config_i.patch
      - patches/0018-add-absl_string_view-target.patch
      - patches/0019-add-absl_nullability-target.patch
      - patches/0020-add-absl_prefetch-target.patch
      - patches/0021-add-absl_die_if_null-target.patch
      - patches/0022-add-absl_crc32c-targets.patch
      - patches/0023-add-kernel_timeout_internal-target.patch
      - patches/0024-work-around-for-warning-that-clang-falsely-treats-as.patch
      - patches/0025-Hardcode-BUILD_PREFIX-in-build_pip_package.patch
      - patches/0026-Only-link-to-sparse_core_layout_proto_cc-headers.patch
      - patches/0027-Protobuf-5-compatability.patch
      # https://github.com/tensorflow/tensorflow/pull/86413
      - patches/0028-Avoid-linking-with-internal-nvrtc.patch
      - patches/0029-remove-dependencies-to-libcuda.patch
      # adjust patch 0004 for newer absl -- hmaarrfk - 2025/07/06
      - patches/0030-Fixup-pybind11_protobuf.patch
      - patches/0031-Update-linkages-for-new-absl-organization.patch
      # Already included in the release after 2.19.0
      - patches/0032-Remove-ambiguous-inherited-constructor-in-default_qu.patch
      # these came from https://git.yoctoproject.org/meta-tensorflow/tree/recipes-framework/tensorflow/files
      # check every release there for patches in the future
      # - patches/0033-third_party-ducc-fix-ambiguous-failure.patch
      # - patches/0034-third_party-tf_runtime-fix-compile-failure.patch
      # - patches/0035-support-to-build-with-gcc-15.patch
      - patches/0036-third_party-eigen_archive-workaround-ice-failure-whi.patch
      # for our system absl
      - patches/0037-add-absl_tracing_internal.patch
      # for the megabuild
      - patches/0038-Fix-building-different-python-wheels-from-one-python.patch
      - patches/0039-Fix-matmul-unused-result-error.patch
      - patches/0040-Support-cuda-12.8.patch
      - patches/0041-Disable-profiler.patch
      - patches/0042-bump-h5py-req.patch     # [aarch64]
      - patches/0043-cross-arch-config.patch  #Â [aarch64 and target_platform != build_platform]
  - url: https://github.com/tensorflow/estimator/archive/refs/tags/v{{ estimator_version.replace(".rc", "-rc") }}.tar.gz
    sha256: 2d7e100b1878084da34b5e23b49a0cbb5ee8a7add74b7dd189a82ada1cf85530
    folder: tensorflow-estimator

build:
  number: {{ build }}
  skip: true  # [win]
  # TODO: debug issues with CUDA cross-compilation
  skip: true  # [aarch64 and cuda_compiler_version != "None"]

requirements:
  build:
    - perl                                   # [linux]
    - python 3.12.*                          # [build_platform != target_platform]
    - cython                                 # [build_platform != target_platform]
    - cross-python_{{ target_platform }}     # [build_platform != target_platform]
    - nsync                                  # [build_platform != target_platform]
    - snappy                                 # [build_platform != target_platform]
    - giflib                                 # [build_platform != target_platform]
    - libjpeg-turbo                          # [build_platform != target_platform]
    - icu                                    # [build_platform != target_platform]
    - libpng                                 # [build_platform != target_platform]
    - flatbuffers                            # [build_platform != target_platform]
    - onednn                                 # [build_platform != target_platform]
    - onednn-cpu-threadpool                  # [build_platform != target_platform]
    - pybind11                               # [build_platform != target_platform]
    - numpy                                  # [build_platform != target_platform]
    - {{ compiler('c') }}
    - {{ stdlib("c") }}
    - {{ compiler('cxx') }}
    - {{ compiler('cuda') }}                 # [cuda_compiler_version != "None"]
    - x86_64-microarch-level  {{ microarch_level }}  # [linux and x86_64]
    - bazel 6.*
    - bazel-toolchain
    - bazel-toolchain <0.3                   # [osx]
    - libgrpc
    - libprotobuf
    - nasm
    - patchelf
    - sed
    - rsync
    # realpath is not available from the docker image for cuda <= 10.2
    # so we install coreutils here
    - coreutils  # [cuda_compiler_version != "None"]
    - zlib       # [build_platform != target_platform]
    - libcurl    # [build_platform != target_platform]
  host:
    # GPU requirements for CUDA
    - cudnn      # [cuda_compiler_version != "None"]
    - nccl       # [cuda_compiler_version != "None"]
    - cuda-version {{ cuda_compiler_version }}  # [cuda_compiler_version != "None"]
    - cuda-cupti-dev    # [(cuda_compiler_version or "").startswith("12")]
    - cuda-cudart-dev   # [(cuda_compiler_version or "").startswith("12")]
    - cuda-nvml-dev     # [(cuda_compiler_version or "").startswith("12")]
    - cuda-nvtx-dev     # [(cuda_compiler_version or "").startswith("12")]
    - libcublas-dev     # [(cuda_compiler_version or "").startswith("12")]
    - libcusolver-dev   # [(cuda_compiler_version or "").startswith("12")]
    - libcurand-dev     # [(cuda_compiler_version or "").startswith("12")]
    - libcufft-dev      # [(cuda_compiler_version or "").startswith("12")]
    - libcusparse-dev   # [(cuda_compiler_version or "").startswith("12")]
    - libnvjitlink-dev  # [(cuda_compiler_version or "").startswith("12")]
    # If 3.12 is changed, edit recipe/build_pkg.sh too
    - python 3.12.*
    # conda build requirements
    - pip
    - setuptools
    - packaging
    - zlib
    - libpng
    - libcurl
    - curl         # [win]
    - unzip        # [not win]
    - zip          # [not win]
    - m2-unzip     # [win]
    - m2-zip       # [win]
    - openjdk >=8
    - nsync
    # TF_SYSTEM_LIBS, see usage in
    # https://github.com/tensorflow/tensorflow/blob/v{{ version }}/third_party/systemlibs/syslibs_configure.bzl
    # their versions are specified in
    # https://github.com/tensorflow/tensorflow/blob/v{{ version }}/tensorflow/workspace2.bzl
    # but so far there have been no problems with leaving these
    # unpinned; though some restrictions come in for packages
    # that are also listed as a requirement for the pip_package.
    - libabseil
    - astor
    - cython
    - dill
    - giflib
    - libgrpc
    - flatbuffers
    - icu
    - libjpeg-turbo
    - libpng
    - libprotobuf
    - libprotobuf-python-headers
    - openssl
    - pybind11
    - sqlite
    - snappy
    - zlib
    - ml_dtypes >={{ ml_dtypes_version }},<1.0

outputs:
  - name: libtensorflow_framework
    script: cp_libtensorflow_framework.sh
    build:
      skip: true  # [win]
      string: cuda{{ cuda_compiler_version | replace('.', '') }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != "None"]
      string: cpu_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version == "None"]
      run_exports:
        # tensorflow makes no ABI guarantees, need to pin to what we built with
        - libtensorflow_framework {{ version }}
    requirements:
      # build requirements needs to pick up the compiler run_exports
      build:
        - {{ compiler('c') }}
        - {{ stdlib("c") }}
        - {{ compiler('cxx') }}
        # Keep the cuda compiler here since it helps package solvers
        # decide on the cuda variant
        # https://github.com/conda-forge/tensorflow-feedstock/issues/162
        - {{ compiler('cuda') }}  # [cuda_compiler_version != "None"]
        - x86_64-microarch-level  {{ microarch_level }}  # [linux and x86_64]
      # host requirements to pick up run_exports
      host:
        - libabseil
        - giflib
        - libgrpc
        - icu
        - libjpeg-turbo
        - libcurl
        - libpng
        - libprotobuf
        - openssl
        - snappy
        - sqlite
        - zlib
      run:
        # avoid that people without GPUs needlessly download ~200-300MB
        - __cuda  # [cuda_compiler_version != "None"]
    test:
      commands:
        - test -f $PREFIX/lib/libtensorflow_framework${SHLIB_EXT}  # [cuda_compiler_version == "None"]
        - test ! -f $PREFIX/lib/libtensorflow${SHLIB_EXT}  # [cuda_compiler_version == "None"]

  # 2021/12/29: hmaarrfk
  # as of tensorflow 2.7.0 we need the tensorflow-base package to break
  # circular dependency when buliding tensorflow extra packages This annoying
  # circularity is broken upstream by the fact that they have to bootstrap
  # their builds
  - name: tensorflow-base
    script: build_pkg.sh  # [unix]
    script: build_pkg.bat  # [win]
    build:
      # tensorflow 2.18 doesn't support py313 until 2.20, see
      # https://github.com/tensorflow/tensorflow/issues/78774
      skip: true  # [py==313]
      string: cuda{{ cuda_compiler_version | replace('.', '') }}py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != "None"]
      string: cpu_py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version == "None"]
      # weigh down cpu implementation and give cuda preference
      track_features:
        - tensorflow-cpu          # [cuda_compiler_version == "None"]
      entry_points:
        - tflite_convert = tensorflow.lite.python.tflite_convert:main
        - toco = tensorflow.lite.python.tflite_convert:main
        - saved_model_cli = tensorflow.python.tools.saved_model_cli:main
        - import_pb_to_tensorboard=tensorflow.python.tools.import_pb_to_tensorboard:main
        # The tensorboard package adds this entry point.
        # - tensorboard = tensorboard.main:run_main
        - tf_upgrade_v2 = tensorflow.tools.compatibility.tf_upgrade_v2_main:main
    requirements:
      # build requirements needs to pick up the compiler run_exports
      build:
        - {{ compiler('c') }}
        - {{ stdlib("c") }}
        - {{ compiler('cxx') }}
        - {{ compiler('cuda') }}              # [cuda_compiler_version != "None"]
        - x86_64-microarch-level  {{ microarch_level }}  # [linux and x86_64]
        - python                              # [build_platform != target_platform]
        - cross-python_{{ target_platform }}  # [build_platform != target_platform]
      host:
        # GPU reuqirements
        - cudnn                   # [cuda_compiler_version != "None"]
        - nccl                    # [cuda_compiler_version != "None"]
        - cuda-version {{ cuda_compiler_version }}  # [cuda_compiler_version != "None"]
        - cuda-cupti-dev    # [(cuda_compiler_version or "").startswith("12")]
        - cuda-cudart-dev   # [(cuda_compiler_version or "").startswith("12")]
        - cuda-nvml-dev     # [(cuda_compiler_version or "").startswith("12")]
        - cuda-nvtx-dev     # [(cuda_compiler_version or "").startswith("12")]
        - libcublas-dev     # [(cuda_compiler_version or "").startswith("12")]
        - libcusolver-dev   # [(cuda_compiler_version or "").startswith("12")]
        - libcurand-dev     # [(cuda_compiler_version or "").startswith("12")]
        - libcufft-dev      # [(cuda_compiler_version or "").startswith("12")]
        - libcusparse-dev   # [(cuda_compiler_version or "").startswith("12")]
        - libnvjitlink-dev  # [(cuda_compiler_version or "").startswith("12")]
        # conda build requirements
        - python
        - pip
        - setuptools
        - packaging
        - wheel
        # TF_SYSTEM_LIBS
        - libabseil
        - astor
        - cython
        - dill
        - giflib
        - libgrpc
        - flatbuffers
        - icu
        - libjpeg-turbo
        - libcurl
        - libpng
        - libprotobuf
        - libprotobuf-python-headers
        - openssl
        - pybind11
        - snappy
        - sqlite
        - zlib
        # requirements specified by the package itself, see
        # github.com/tensorflow/tensorflow/blob/v{{ version }}/tensorflow/tools/pip_package/setup.py
        - absl-py >=1.0.0
        - astunparse >=1.6.0
        - gast >=0.2.1,!=0.5.0,!=0.5.1,!=0.5.2
        - google-pasta >=0.1.1
        - h5py >=3.11
        - ml_dtypes >={{ ml_dtypes_version }},<1.0
        - numpy
        - opt_einsum >=2.3.2
        # simplified compared to upstream due to constraints arising through libprotobuf
        - protobuf >=5.28
        - python-flatbuffers >=24.3.25
        - requests >=2.21.0,<3
        - six >=1.12
        - termcolor >=1.1.0
        - typing_extensions >=3.6.6
        - wrapt >=1.11.0
        # TF-API needs to move in sync
        - tensorboard >=2.19,<2.20
        - keras >=3.5
        - {{ pin_subpackage("libtensorflow_framework", exact=True) }}
        - {{ pin_subpackage("libtensorflow_cc", exact=True) }}
      run:
        - python
        - packaging
        - absl-py >=1.0.0
        - astunparse >=1.6.0
        - gast >=0.2.1,!=0.5.0,!=0.5.1,!=0.5.2
        - google-pasta >=0.1.1
        - grpcio {{ libgrpc }}.*
        - h5py >=3.11
        - ml_dtypes >={{ ml_dtypes_version }},<1.0
        - opt_einsum >=2.3.2
        - protobuf >=5.26
        - python-flatbuffers >=24.3.25
        - requests >=2.21.0,<3
        - six >=1.12
        - termcolor >=1.1.0
        - typing_extensions >=3.6.6
        - wrapt >=1.11.0
        # TF-API needs to move in sync
        - tensorboard >=2.19,<2.20
        - keras >=3.5
        # avoid that people without GPUs needlessly download ~0.5-1GB
        - __cuda                                                  # [cuda_compiler_version != "None"]
        # https://github.com/conda-forge/tensorflow-feedstock/issues/296#issuecomment-1835781851
        - cuda-nvcc-tools                                         # [(cuda_compiler_version or "").startswith("12")]
        - {{ pin_subpackage("libtensorflow_framework", exact=True) }}
        - {{ pin_subpackage("libtensorflow_cc", exact=True) }}
    # TODO: decide on the name of the package
    # run_constrained:
    #   What is the difference between these two packages?
    #   - tensorflow-io-gcs-filesystem >=0.21.0
    #   - tensorflow-io >=0.21.0
    test:
      commands:
        - exit 0

  - name: tensorflow
    build:
      # tensorflow 2.18 doesn't support py313 until 2.20, see
      # https://github.com/tensorflow/tensorflow/issues/78774
      skip: true  # [py==313]
      string: cuda{{ cuda_compiler_version | replace('.', '') }}py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != "None"]
      string: cpu_py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version == "None"]
      # weigh down cpu implementation and give cuda preference
      track_features:
        - tensorflow-cpu          # [cuda_compiler_version == "None"]
    requirements:
      host:
        # Require python so that the CONDA_PY gets populated
        - python
        # Keep the cuda version here since it helps package solvers
        # decide on the cuda variant
        - cuda-version {{ cuda_compiler_version }}  # [cuda_compiler_version != "None"]
      run:
        - python
        - {{ pin_subpackage('tensorflow-base', exact=True) }}
        - {{ pin_subpackage('tensorflow-estimator', exact=True) }}
        # avoid that people without GPUs needlessly download ~0.5-1GB
        # This also helps mamba give preference to the CPU build
        - __cuda  # [cuda_compiler_version != "None"]
    test:
      files:
        - test_tensorflow.py
      requires:
        - pip
      imports:
        - tensorflow                 # [build_platform == target_platform]
      commands:
        - pip check                  # [build_platform == target_platform]
        - cat test_tensorflow.py     # [unix]
        - python test_tensorflow.py  # [build_platform == target_platform]
        - tf_upgrade_v2 --help       # [build_platform == target_platform]
        # --help exits with exit code 1
        - test -x $PREFIX/bin/saved_model_cli  # [unix]
        - tflite_convert --help      # [build_platform == target_platform]
        - toco --help                # [build_platform == target_platform]
        - python -c 'import tensorflow as tf; assert tf.test.is_built_with_cuda()'      # [cuda_compiler_version != "None" and build_platform == target_platform]
        - python -c 'import tensorflow as tf; assert not tf.test.is_built_with_cuda()'  # [cuda_compiler_version == "None" and build_platform == target_platform]
        # See https://github.com/conda-forge/tensorflow-feedstock/issues/364
        - python -c "import tensorflow as tf;graph = tf.function(lambda x:x).get_concrete_function(1.).graph;tf.compat.v1.train.export_meta_graph(graph=graph,graph_def=graph.as_graph_def())"  # [build_platform == target_platform]

  - name: tensorflow-estimator
    script: build_estimator.sh  # [unix]
    script: build_estimator.bat  # [win]
    build:
      # tensorflow 2.18 doesn't support py313 until 2.20, see
      # https://github.com/tensorflow/tensorflow/issues/78774
      skip: true  # [py==313]
      string: cuda{{ cuda_compiler_version | replace('.', '') }}py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != "None"]
      string: cpu_py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version == "None"]
    requirements:
      build:
        - {{ compiler('c') }}
        - {{ stdlib("c") }}
        - {{ compiler('cxx') }}
        # Keep the cuda compiler here since it helps package solvers
        # decide on the cuda variant
        # https://github.com/conda-forge/tensorflow-feedstock/issues/162
        - {{ compiler('cuda') }}                   # [cuda_compiler_version != "None"]
        - x86_64-microarch-level  {{ microarch_level }}  # [linux and x86_64]
        - bazel 6.*
        - bazel-toolchain
        - python                                   # [build_platform != target_platform]
        - cross-python_{{ target_platform }}       # [build_platform != target_platform]
        - libabseil                                # [build_platform != target_platform]
        - libgrpc                                  # [build_platform != target_platform]
        - icu                                      # [build_platform != target_platform]
        - {{ pin_subpackage('tensorflow-base') }}  # [build_platform != target_platform]
      host:
        - python
        - pip
        - packaging
        - setuptools
        - wheel
        # This ensures that a consistent version of openssl is chosen between
        # all packages.
        # https://github.com/conda-forge/conda-forge.github.io/issues/1528
        - openssl
        - {{ pin_subpackage('tensorflow-base', exact=True) }}
        # Keep the cuda version here since it helps package solvers
        # decide on the cuda variant
        - cuda-version {{ cuda_compiler_version }}  # [cuda_compiler_version != "None"]
      run:
        - python
        - {{ pin_subpackage('tensorflow-base', exact=True) }}
    test:
      requires:
        - pip
      commands:
        - pip check  # [build_platform == target_platform]

  - name: libtensorflow
    script: cp_libtensorflow.sh
    build:
      skip: true  # [win]
      string: cuda{{ cuda_compiler_version | replace('.', '') }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != "None"]
      string: cpu_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version == "None"]
      run_exports:
        # tensorflow makes no ABI guarantees, need to pin to what we built with
        - libtensorflow {{ version }}
    requirements:
      # build requirements needs to pick up the compiler run_exports
      build:
        - {{ compiler('c') }}
        - {{ stdlib("c") }}
        - {{ compiler('cxx') }}
        # Keep the cuda compiler here since it helps package solvers
        # decide on the cuda variant
        # https://github.com/conda-forge/tensorflow-feedstock/issues/162
        - {{ compiler('cuda') }}  # [cuda_compiler_version != "None"]
        - x86_64-microarch-level  {{ microarch_level }}  # [linux and x86_64]
      # host requirements to pick up run_exports
      host:
        - libabseil
        - giflib
        - libgrpc
        - icu
        - libjpeg-turbo
        - libcurl
        - libpng
        - libprotobuf
        - openssl
        - snappy
        - sqlite
        - zlib
        - {{ pin_subpackage("libtensorflow_framework", exact=True) }}
      run:
        # avoid that people without GPUs needlessly download ~200-300MB
        - __cuda  # [cuda_compiler_version != "None"]
        - {{ pin_subpackage("libtensorflow_framework", exact=True) }}
    test:
      files:
        - test_libtensorflow.sh
        - test_c.c
      requires:
        - {{ compiler('c') }}
      commands:
        - test -f $PREFIX/lib/libtensorflow${SHLIB_EXT}  # [cuda_compiler_version == "None"]
        - ./test_libtensorflow.sh                        # [cuda_compiler_version == "None" and build_platform == target_platform]

  - name: libtensorflow_cc
    script: cp_libtensorflow_cc.sh
    build:
      skip: true  # [win]
      string: cuda{{ cuda_compiler_version | replace('.', '') }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != "None"]
      string: cpu_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version == "None"]
      run_exports:
        # tensorflow makes no ABI guarantees, need to pin to what we built with
        - libtensorflow_cc {{ version }}
    requirements:
      # build requirements needs to pick up the compiler run_exports
      build:
        - {{ compiler('c') }}
        - {{ stdlib("c") }}
        - {{ compiler('cxx') }}
        # Keep the cuda compiler here since it helps package solvers
        # decide on the cuda variant
        # https://github.com/conda-forge/tensorflow-feedstock/issues/162
        - {{ compiler('cuda') }}  # [cuda_compiler_version != "None"]
        - x86_64-microarch-level  {{ microarch_level }}  # [linux and x86_64]
        - rsync
      # host requirements to pick up run_exports
      host:
        - flatbuffers
        - giflib
        - icu
        - libabseil
        - libcurl
        - libgrpc
        - libjpeg-turbo
        - libpng
        - libprotobuf
        - openssl
        - snappy
        - sqlite
        - zlib
        - {{ pin_subpackage("libtensorflow_framework", exact=True) }}
      run:
        - libml_dtypes-headers >={{ libml_dtypes_version }},<0.6
        # avoid that people without GPUs needlessly download ~200-300MB
        - __cuda  # [cuda_compiler_version != "None"]
        - {{ pin_subpackage("libtensorflow_framework", exact=True) }}
    test:
      files:
        - test_libtensorflow_cc.sh
        - test_cc.cc
      requires:
        - {{ compiler('cxx') }}
      commands:
        - test -f $PREFIX/lib/libtensorflow_cc${SHLIB_EXT}  # [not win and cuda_compiler_version == "None"]
        - ./test_libtensorflow_cc.sh                        # [not win and cuda_compiler_version == "None" and build_platform == target_platform]

  - name: tensorflow-cpu
    build:
      string: cpu_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}
      skip: True  # [cuda_compiler_version != "None"]
    requirements:
      run:
        - tensorflow {{ version }} cpu*_{{ PKG_BUILDNUM }}
    test:
      imports:
        - tensorflow                 # [build_platform == target_platform]

  - name: tensorflow-gpu
    build:
      string: cuda{{ cuda_compiler_version | replace('.', '') }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}
      skip: True  # [cuda_compiler_version == "None"]
    requirements:
      run:
        - tensorflow {{ version }} cuda{{ cuda_compiler_version | replace('.', '') }}*_{{ PKG_BUILDNUM }}
    test:
      imports:
        - tensorflow                 # [build_platform == target_platform]

  - name: tensorflow-sse3
    build:
      skip: True  # [(not x86_64) or microarch_level != 1]
      # tensorflow 2.18 doesn't support py313 until 2.20, see
      # https://github.com/tensorflow/tensorflow/issues/78774
      skip: true  # [py==313]
      string: cuda{{ cuda_compiler_version | replace('.', '') }}py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != "None"]
      string: cpu_py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}                                                # [cuda_compiler_version == "None"]
    requirements:
      host:
        # need to build per python version to pin to exact tensorflow package-hashes corresponding to sse3
        - python
      run:
        - {{ pin_subpackage("tensorflow", exact=True) }}
    test:
      imports:
        - tensorflow

  - name: tensorflow-avx2
    build:
      skip: True  # [(not x86_64) or microarch_level != 3]
      # tensorflow 2.18 doesn't support py313 until 2.20, see
      # https://github.com/tensorflow/tensorflow/issues/78774
      skip: true  # [py==313]
      string: cuda{{ cuda_compiler_version | replace('.', '') }}py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != "None"]
      string: cpu_py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}                                                # [cuda_compiler_version == "None"]
    requirements:
      host:
        # need to build per python version to pin to exact tensorflow package-hashes corresponding to avx2
        - python
      run:
        - {{ pin_subpackage("tensorflow", exact=True) }}
    test:
      imports:
        - tensorflow

  - name: tensorflow-avx512
    build:
      skip: True  # [(not x86_64) or microarch_level != 4]
      # tensorflow 2.18 doesn't support py313 until 2.20, see
      # https://github.com/tensorflow/tensorflow/issues/78774
      skip: true  # [py==313]
      string: cuda{{ cuda_compiler_version | replace('.', '') }}py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != "None"]
      string: cpu_py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}                                                # [cuda_compiler_version == "None"]
    requirements:
      host:
        # need to build per python version to pin to exact tensorflow package-hashes corresponding to avx512
        - python
      run:
        - {{ pin_subpackage("tensorflow", exact=True) }}
    test:
      imports:
        - tensorflow

about:
  home: http://tensorflow.org/
  license: Apache-2.0
  license_file: LICENSE
  license_family: Apache
  summary: TensorFlow is an end-to-end open source platform for machine learning.
  description: |
    TensorFlow offers multiple levels of abstraction so you can choose the
    right one for your needs. Build and train models by using the high-level
    Keras API, which makes getting started with TensorFlow and machine learning
    easy.
  dev_url: https://github.com/tensorflow/tensorflow
  doc_url: https://www.tensorflow.org/get_started/get_started
  doc_source_url: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/docs_src

extra:
  feedstock-name: tensorflow
  recipe-maintainers:
    - isuruf
    - ngam
    - farhantejani
    - ghego
    - h-vetinari
    - hajapy
    - jschueller
    - njzjz
    - waitingkuo
    - xhochy
    - hmaarrfk
    - wolfv
