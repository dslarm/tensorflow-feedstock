From e9edf6f421d091b5c51f4022bedf67e9a0bc2ca9 Mon Sep 17 00:00:00 2001
From: aravindhbalaji1985 <aravindhbalaji@gmail.com>
Date: Mon, 25 Aug 2025 15:15:14 -0700
Subject: [PATCH 43/44] Support for TFv2.20 to compile with CUDA v12.9.1

---
 tensorflow/core/kernels/concat_lib_gpu_impl.cu.cc     |  2 +-
 .../core/kernels/dynamic_partition_op_gpu.cu.cc       |  6 +++++-
 tensorflow/core/kernels/split_lib_gpu.cu.cc           |  2 +-
 tensorflow/core/kernels/where_op_gpu.cu.h             | 11 +++++++++++
 4 files changed, 18 insertions(+), 3 deletions(-)

diff --git a/tensorflow/core/kernels/concat_lib_gpu_impl.cu.cc b/tensorflow/core/kernels/concat_lib_gpu_impl.cu.cc
index 031464dfdd9..b4fe8ae6977 100644
--- a/tensorflow/core/kernels/concat_lib_gpu_impl.cu.cc
+++ b/tensorflow/core/kernels/concat_lib_gpu_impl.cu.cc
@@ -70,7 +70,7 @@ __global__ void concat_variable_kernel(
   IntType num_inputs = input_ptr_data.size;
 
   // verbose declaration needed due to template
-  GPU_DYNAMIC_SHARED_MEM_DECL(sizeof(T), unsigned char, smem);
+  GPU_DYNAMIC_SHARED_MEM_DECL(8, unsigned char, smem);
   IntType* smem_col_scan = reinterpret_cast<IntType*>(smem);
 
   if (useSmem) {
diff --git a/tensorflow/core/kernels/dynamic_partition_op_gpu.cu.cc b/tensorflow/core/kernels/dynamic_partition_op_gpu.cu.cc
index ae3fe6d140f..737e22e5b9f 100644
--- a/tensorflow/core/kernels/dynamic_partition_op_gpu.cu.cc
+++ b/tensorflow/core/kernels/dynamic_partition_op_gpu.cu.cc
@@ -410,7 +410,11 @@ class DynamicPartitionOpGPU : public AsyncOpKernel {
                                             num_partitions_);
 
 #if GOOGLE_CUDA
-    cub::ConstantInputIterator<int32> values_in(1);
+    #if THRUST_VERSION >= 200802
+        thrust::constant_iterator<int32> values_in(1);
+    #else
+        cub::ConstantInputIterator<int32> values_in(1);
+    #endif
 #elif TENSORFLOW_USE_ROCM
     using ConstantInputIterator =
         ::rocprim::constant_iterator<int32, ptrdiff_t>;
diff --git a/tensorflow/core/kernels/split_lib_gpu.cu.cc b/tensorflow/core/kernels/split_lib_gpu.cu.cc
index 90b28292ac0..e395d4f12f5 100644
--- a/tensorflow/core/kernels/split_lib_gpu.cu.cc
+++ b/tensorflow/core/kernels/split_lib_gpu.cu.cc
@@ -120,7 +120,7 @@ __global__ void split_v_kernel(const T* __restrict__ input_ptr,
   int num_outputs = output_ptr_data.size;
 
   // verbose declaration needed due to template
-  GPU_DYNAMIC_SHARED_MEM_DECL(sizeof(T), unsigned char, smem);
+  GPU_DYNAMIC_SHARED_MEM_DECL(2, unsigned char, smem);
   IntType* smem_col_scan = reinterpret_cast<IntType*>(smem);
 
   if (useSmem) {
diff --git a/tensorflow/core/kernels/where_op_gpu.cu.h b/tensorflow/core/kernels/where_op_gpu.cu.h
index 5eb03ec60ad..3de25b7a82c 100644
--- a/tensorflow/core/kernels/where_op_gpu.cu.h
+++ b/tensorflow/core/kernels/where_op_gpu.cu.h
@@ -233,6 +233,17 @@ class WhereOutputIterator {
     return *(ptr_ + (valid ? (NDIM * n) : 0));
   }
 
+
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE reference operator*() const {
+    // Dereference the current pointer
+    return *ptr_;
+  }
+
+
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE self_type operator+(std::ptrdiff_t n) const {
+    return self_type(ptr_ + NDIM * n, max_row_);
+  }
+
  private:
   int64* ptr_;
   const Eigen::DenseIndex max_row_;
